P8105_HW2_ah4028
================
Austin Hsin
2023-09-28

## Problem 0 - Setup

Setup code to load `tidyverse` and `readxl` library

``` r
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
```

## Problem 1 - Data Import, Cleaning, Merging

Importing, cleaning, and merging `pols-month.csv`, `snp.csv`, and
`unemployment.csv`

``` r
# Import and cleaning of 'pols_month_data'
pols_month_data = read.csv(file = "./fivethirtyeight_datasets/pols-month.csv")|>
  separate("mon", into = c("year", "month", "day"), convert = TRUE)|>
  mutate(month = recode(month, 
                        "1" = "Jan",
                        "2" = "Feb",
                        "3" = "Mar",
                        "4" = "Apr",
                        "5" = "May",
                        "6" = "Jun",
                        "7" = "Jul",
                        "8" = "Aug",
                        "9" = "Sep",
                        "10" = "Oct",
                        "11" = "Nov",
                        "12" = "Dec"))|>
  mutate(president = case_when(prez_dem == "1" ~ 'dem',
                               prez_gop == "1" ~ 'gop'))|>
  select(-prez_dem,-prez_gop,-day)

# Import and cleaning 'snp.csv'
snp_data = read.csv(file = "./fivethirtyeight_datasets/snp.csv")|>
   separate("date", into = c("month", "day", "year"), convert = TRUE)|>
  arrange(month)|>
  mutate(month = recode(month, 
                        "1" = "Jan",
                        "2" = "Feb",
                        "3" = "Mar",
                        "4" = "Apr",
                        "5" = "May",
                        "6" = "Jun",
                        "7" = "Jul",
                        "8" = "Aug",
                        "9" = "Sep",
                        "10" = "Oct",
                        "11" = "Nov",
                        "12" = "Dec"))|>
  mutate(year = ifelse(year > 49, 1900 + year, 2000 + year))|>
  select(year, month, close,-day)|>
  arrange(year)

# Import and cleaning 'unemployment.csv'
unemployment_data = read.csv(file = "./fivethirtyeight_datasets/unemployment.csv")|>
  pivot_longer(Jan:Dec, values_to = "pct")|>
  rename(month = name, year = Year)

# Merging pols_month_data, snp_data, and unemployment_data
pols_snp_data = full_join(snp_data, pols_month_data, by = c("year", "month"))
five_thirty_eight_merged_data = full_join(pols_snp_data, unemployment_data, by = c("year", "month"))
```

As a note for whoever is grading this, inline with my github commits, I
had solved problem 1 my own way prior to the release of the solution. I
have kept it as such as my cleaning and merging produced a similar
dataset with different naming conventions.

The `pols_month` dataset contains data regarding the number of
politicians, including governors, senators, and president based on party
affiliation on a monthly basis from 1947 to 2015. The `snp` dataset
contains data regarding the monthly closing values of the S&P 500 stock
market index from 1950 to 2015. The `unemployment` dataset contains data
regarding the unemployment rate at the end of each month from 1948 to
2015.

The resulting merged dataset, \`five_thirty_eight_merged_data has 11
columns and 828 rows and has a complete data year range from 1950 to
2015. Prior to January 1950 and after July 2015, there are a range of
missing values from the S&P500 close to the unemployment percentage.

## Problem 2 - Trash Wheel Dataset

Importing and cleaning of 3 different trash wheel datasets

``` r
#Import and cleaning of Mr. Trash Wheel data
mr.trash_wheel_data = read_excel("./202309 Trash Wheel Collection Data.xlsx", 
sheet = 1, 
range = ("A2:N586"),
col_types = c("numeric","text","numeric","date","numeric","numeric","numeric","numeric","numeric","numeric","numeric","numeric","numeric","text"))|>
  janitor::clean_names()|>
  mutate(homes_powered_new = weight_tons*16.67, #Adding new variables
       name = "Mr. Trash Wheel")
```

Here we imported and cleaned the Mr. Trash Wheel data from sheet 1 of
the Trash Wheel Collection Data as well as included a new variable
`homes_powered_new`, based on the homes powered note, and `name`.

``` r
#Import and cleaning of Professor Trash Wheel data
professor_trash_wheel_data = read_excel("./202309 Trash Wheel Collection Data.xlsx", 
sheet = 2, 
range = ("A2:M108"),
col_types = c("numeric","text","numeric","date","numeric","numeric","numeric","numeric","numeric","numeric","numeric","numeric","text"))|>
  janitor::clean_names()|>
  mutate(homes_powered_new = weight_tons*16.67, #Adding new variables
       name = "Professor Trash Wheel")
```

Here we similarly imported and cleaned the Professor Trash Wheel data
from sheet 2 of the Trash Wheel Collection Data as well as included a
new variable `homes_powered_new`, based on the homes powered note, and
`name`.

``` r
#Import and cleaning of Gywnnda Trash Wheel data
gywnnda_trash_wheel_data = read_excel("./202309 Trash Wheel Collection Data.xlsx", 
sheet = 4, 
range = ("A2:L157"),
col_types = c("numeric","text","numeric","date","numeric","numeric","numeric","numeric","numeric","numeric","numeric", "text"))|>
  janitor::clean_names()|>
  mutate(homes_powered_new = weight_tons*16.67, #Adding new variables
       name = "Gywnnda Trash Wheel")
```

Here we similarly imported and cleaned the Gywnnda Trash Wheel data from
sheet 4 of the Trash Wheel Collection Data as well as included a new
variable `homes_powered_new`, based on the homes powered note, and
`name`.

# Merged Trash Wheel Dataset

Merging all three trash wheel datasets and describing the resulting
dataset

``` r
#Bind Rows all three trash wheel data sets
trash_wheel_tidy = bind_rows(mr.trash_wheel_data, professor_trash_wheel_data, gywnnda_trash_wheel_data)
```

Resulting `trash_wheel_tidy` dataset has 16 columns and 845 rows that
includes variables such as `dumpster`, `date`, `weight` and `volume` of
trash, multiple varieties of trash types, `name` identifier for each
trash wheel, and the new `powered_homes_new` variable that multiplies
weight of trash by (500/30) = 16.67.

Total trash weight collected by Professor Trash Wheel is 216.26.

Total number of cigarette butts collected by Gywnnda Trash Wheel in July
2021 is 1.63^{4}.

## Problem 3 - MCI Datasets

Importing and Cleaning of Baseline MCI and Amyloid MCI datasets

``` r
#Importing MCI Baseline Data and cleaning names
MCI_baseline_data = read.csv("./data_mci/MCI_baseline.csv")|>
  janitor::clean_names()|>
  rename(
    ID = x,
    Baseline_Age = `age_at_the_study_baseline`,
    Sex = `x1_male_0_female`,
    APOE4 = `x1_apoe4_carrier_0_apoe4_non_carrier`,
    MCI_Onset = `age_at_the_onset_of_mci_missing_if_a_subject_remains_mci_free_during_the_follow_up_period`,
        )
```

There were 484 participants that were recruited in total.

# Tidying MCI_baseline_data

Tidying MCI_baseline_data and answering questions about the dataset

``` r
#Recoding variables and removing those without age of MCI onset
MCI_baseline_tidy_data = MCI_baseline_data|>
  mutate(Sex = recode(Sex, 
                          "1" = "Male", 
                          "0" = "Female"))|>
  mutate(APOE4= recode(APOE4,
                       `1` = "Carrier",
                       `0` = "Non-Carrier"))|>
  mutate(Baseline_Age = as.numeric(Baseline_Age))|>
  mutate(MCI_Onset = as.integer(MCI_Onset))|>
  mutate(ID = as.numeric(ID))|>
  filter(MCI_Onset != ".")
```

After removing those without a MCI age of onset value, there are 97
subjects with MCI.

Average baseline age is 69.81

The proportion of women who are APOE4 carriers is 0.65

# MCI Amyloid Dataset

Importing and tidying amyloid dataset

``` r
MCI_amyloid_data = read_csv("./data_mci/mci_amyloid.csv", skip=1)|>
  janitor::clean_names()|>
  drop_na()|>
  rename(ID = study_id)|>
  mutate(ID = as.numeric(ID))
```

    ## Rows: 487 Columns: 6
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (5): Baseline, Time 2, Time 4, Time 6, Time 8
    ## dbl (1): Study ID
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

After removing missing values, the number of observations is 347.

# Merging Tidy MCI Baseline and MCI Amyloid Datasets

Merging both datasets by `ID`

``` r
anti_combine_baseline_amyloid = anti_join(MCI_baseline_tidy_data, MCI_amyloid_data, by = "ID")

anti_combine_amyloid_baseline = anti_join(MCI_amyloid_data, MCI_baseline_tidy_data, by = "ID")
```

31 participants are within the MCI baseline dataset, and 281
participants are within the MCI amyloid dataset.

``` r
MCI_combine_baseline_amyloid_data = 
  inner_join(MCI_baseline_tidy_data, MCI_amyloid_data, by = "ID")
```

After combining the tidied baseline and amyloid data, we have full data
on 66 participants.

The average age of those in the full data was 65.83 years old.

The average MCI onset age was 70.03 years old.

The number of female subjects is 33.

The proportion of APOE4 carriers is 0.58.

# Exporting combined MCI dataset

Exporting MCI_combine_baseline_amyloid_data

``` r
write_csv(MCI_combine_baseline_amyloid_data, "./data_mci/MCI_combine_baseline_amyloid.csv")
```
